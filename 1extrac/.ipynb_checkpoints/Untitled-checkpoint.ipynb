{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(IdUbigeo=51010000, Distrito=None, Provincia=None, Departamento='Amazonas', PAIS='Peru', PAIS_DPTO='Peru Amazonas', PAIS_DPTO_PROV='Peru Amazonas ', PAIS_DPTO_PROV_DIST='Peru Amazonas  '),\n",
       " Row(IdUbigeo=51010100, Distrito=None, Provincia='Chachapoyas', Departamento='Amazonas', PAIS='Peru', PAIS_DPTO='Peru Amazonas', PAIS_DPTO_PROV='Peru Amazonas Chachapoyas', PAIS_DPTO_PROV_DIST='Peru Amazonas Chachapoyas '),\n",
       " Row(IdUbigeo=51010101, Distrito='Chachapoyas', Provincia='Chachapoyas', Departamento='Amazonas', PAIS='Peru', PAIS_DPTO='Peru Amazonas', PAIS_DPTO_PROV='Peru Amazonas Chachapoyas', PAIS_DPTO_PROV_DIST='Peru Amazonas Chachapoyas Chachapoyas')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext.getOrCreate()\n",
    "#sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.format('csv').options(header='true', inferschema='true')\\\n",
    "    .load('../ubigeo.csv')\n",
    "df.rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Fam_id|   Nom_fam|\n",
      "+------+----------+\n",
      "|     1|   TABLETA|\n",
      "|     2|INYECTABLE|\n",
      "|     3|SUSPENSION|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostname = \"127.0.0.1\" \n",
    "dbname = \"farmadb\"\n",
    "jdbcPort = 3306\n",
    "username = \"root\"\n",
    "password = \"12345\"\n",
    "jdbc_url = \"jdbc:mysql://{0}:{1}/{2}?user={3}&password={4}\"\\\n",
    "            .format(hostname, jdbcPort, dbname, username, password)\n",
    "\n",
    "query = \"(select * from FAMILIA) t1_alias\"\n",
    "df1 = sqlContext.read.format('jdbc')\\\n",
    "        .options(driver = 'com.mysql.jdbc.Driver', url=jdbc_url, dbtable=query).load()\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fam_id</th>\n",
       "      <th>Nom_fam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TABLETA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>INYECTABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SUSPENSION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fam_id     Nom_fam\n",
       "0       1     TABLETA\n",
       "1       2  INYECTABLE\n",
       "2       3  SUSPENSION"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facebook-sdk in /home/asullom/anaconda3/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: requests in /home/asullom/anaconda3/lib/python3.7/site-packages (from facebook-sdk) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/asullom/anaconda3/lib/python3.7/site-packages (from requests->facebook-sdk) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/asullom/anaconda3/lib/python3.7/site-packages (from requests->facebook-sdk) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/asullom/anaconda3/lib/python3.7/site-packages (from requests->facebook-sdk) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/asullom/anaconda3/lib/python3.7/site-packages (from requests->facebook-sdk) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install facebook-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facebook, urllib3, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "linesRDD= sc.textFile(\"../spark-defaults.conf\")\n",
    "print( type(linesRDD) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '# Licensed to the Apache Software Foundation (ASF) under one or more',\n",
       " '# contributor license agreements.  See the NOTICE file distributed with',\n",
       " '# this work for additional information regarding copyright ownership.',\n",
       " '# The ASF licenses this file to You under the Apache License, Version 2.0',\n",
       " '# (the \"License\"); you may not use this file except in compliance with',\n",
       " '# the License.  You may obtain a copy of the License at',\n",
       " '#',\n",
       " '#    http://www.apache.org/licenses/LICENSE-2.0',\n",
       " '#',\n",
       " '# Unless required by applicable law or agreed to in writing, software',\n",
       " '# distributed under the License is distributed on an \"AS IS\" BASIS,',\n",
       " '# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.',\n",
       " '# See the License for the specific language governing permissions and',\n",
       " '# limitations under the License.',\n",
       " '#',\n",
       " '',\n",
       " '# Default system properties included when running spark-submit.',\n",
       " '# This is useful for setting default environmental settings.',\n",
       " '',\n",
       " '# Example:',\n",
       " '# spark.master                     spark://master:7077',\n",
       " '# spark.eventLog.enabled           true',\n",
       " '# spark.eventLog.dir               hdfs://namenode:8021/directory',\n",
       " '# spark.serializer                 org.apache.spark.serializer.KryoSerializer',\n",
       " '# spark.driver.memory              5g',\n",
       " '# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"',\n",
       " '',\n",
       " 'spark.driver.extraClassPath :/home/asullom/adev/jars/*',\n",
       " 'spark.executor.extraClassPath :/home/asullom/adev/jars/*']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linesRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Default system properties included when running spark-submit.',\n",
       " '# spark.master                     spark://master:7077',\n",
       " '# spark.eventLog.enabled           true',\n",
       " '# spark.eventLog.dir               hdfs://namenode:8021/directory',\n",
       " '# spark.serializer                 org.apache.spark.serializer.KryoSerializer',\n",
       " '# spark.driver.memory              5g',\n",
       " '# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"',\n",
       " 'spark.driver.extraClassPath :/home/asullom/adev/jars/*',\n",
       " 'spark.executor.extraClassPath :/home/asullom/adev/jars/*']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mifilter = linesRDD.filter(lambda line: \"spark\" in line)\n",
    "mifilter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
